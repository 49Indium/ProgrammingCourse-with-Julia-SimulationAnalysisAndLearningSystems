# Unit 7: Working with heterogenous datasets and a view towards machine learning

# Databases

* Relational databases as a concept... 
* Andy to show an example...
* There is a language: SQL....

# Dataframes

Working with tabular data is a central part of data analysis (think Excel). Data has rows (observations) and columns (variables/features). Typically a row would be for an individual, or item, or event. Typically a collumn would be for attributes of the individual, properties of the events, etc. Variables can be numerical, categorical, strings, or even more complex entities (e.g. images).

The datafile `small_olympics.csv` is based on a random sample of rows from a larger dataset avaialbe via [Kaggle](https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results). The original data size in Kaggle, `athlette_events.csv` has over 27,000 rows of data. The `small_olympics.csv` file is a randomly selected subset of 500 rows where we also modified some of the formats of the data file.

We will use `small_olympics.csv` to show basic functionallity of the [DataFrames.jl](https://dataframes.juliadata.org/stable/) and [TypedTables.jl](https://github.com/JuliaData/TypedTables.jl) packages. In a sense these packages are alternatives. Seeing some functionallity from each may be useful for gaining a general understanding of what to expect from such packages. If you work with Python, then using [pandas](https://pandas.pydata.org/) is the common alternative. Similarly if you work with the R language then the built in dataframes are common.


```julia
using DataFrames, CSV
df = CSV.File("../data/small_olympics.csv") |> DataFrame #In Julia f(x) |> g is like g(f(x))
println("Data size: ", size(df))
println("Columns in the data: ", names(df))
```

Here are some data rows:


```julia
df.Event
```

```julia
df.Height
```

As you can see from above, some data can be missing. How many heights are missing?

```julia
ismissing.(df.Height) |> sum
```


* QQQQ - Get dataset:
- Not too many rows, not too little.
- 3-5 correleatd variables.  
- Categorical
- Missing
- Two datasets for join

* Beyond arrays, dictionaries, and such... but not yet in a DB.
* The dataframes package/typedtables.jl - basic usage:
 - Filtering rows.
 - Accessing.
 - Modifying.
 - Copy, DeepCopy, etc....
* Spliting, apply, and `by()`
* Join... 
* Missing values and basic imputation.

* EDA (Exploratory data analysis) StatsPlots.jl

# Memory management

* More on the heap vs. stack. 
* The garbage collector.
* Out-of-core example - working/fetching files.... (DataFrames works with "arrow format" (https://en.wikipedia.org/wiki/Apache_Arrow). Example that implements line by line CSV... and then discuss modern pardigms such as Arrow

# Basic regression and classification Problems

```
using Flux, Flux.Data.MNIST, LinearAlgebra
using Flux: onehotbatch

imgs   = Flux.Data.MNIST.images()
labels = Flux.Data.MNIST.labels()
nTrain = length(imgs)
trainData = vcat([hcat(float.(imgs[i])...) for i in 1:nTrain]...)
trainLabels = labels[1:nTrain]
testImgs = Flux.Data.MNIST.images(:test)
testLabels = Flux.Data.MNIST.labels(:test)
nTest = length(testImgs)
testData = vcat([hcat(float.(testImgs[i])...) for i in 1:nTest]...)

A = [ones(nTrain) trainData]
Adag = pinv(A)
tfPM(x) = x ? +1 : -1
yDat(k) = tfPM.(onehotbatch(trainLabels,0:9)'[:,k+1])
bets = [Adag*yDat(k) for k in 0:9]

classify(input) = findmax([([1 ; input])'*bets[k] for k in 1:10])[2]-1

predictions = [classify(testData[k,:]) for k in 1:nTest]
confusionMatrix = [sum((predictions .== i) .& (testLabels .== j))
				for i in 0:9, j in 0:9]
accuracy = sum(diag(confusionMatrix))/nTest

println("Accuracy: ", accuracy, "\nConfusion Matrix:")
show(stdout, "text/plain", confusionMatrix)
```

```
using Flux.Data.MNIST, DecisionTree, Random
Random.seed!(0)

trainImgs   = MNIST.images()
trainLabels = MNIST.labels()
nTrain = length(trainImgs)
trainData = vcat([hcat(float.(trainImgs[i])...) for i in 1:nTrain]...)

testImgs = MNIST.images(:test)
testLabels = MNIST.labels(:test)
nTest = length(testImgs)
testData = vcat([hcat(float.(testImgs[i])...) for i in 1:nTest]...)

numFeaturesPerTree = 10
numTrees = 40
portionSamplesPerTree = 0.7
maxTreeDepth = 10

model = build_forest(trainLabels, trainData, 
                    numFeaturesPerTree, numTrees, 
                    portionSamplesPerTree, maxTreeDepth)
println("Trained model:")
println(model)

predicted_labels = [apply_forest(model, testData[k,:]) for k in 1:nTest]
accuracy = sum(predicted_labels .== testLabels)/nTest
println("\nPrediction accuracy (measured on test set of size $nTest): ",accuracy)
```

```
using Flux, Flux.Data.MNIST, Statistics, BSON, Random, Plots
using Flux: onehotbatch, onecold, crossentropy
Random.seed!(0)

epochs = 30
eta = 5e-3
batchSize = 1000
trainRange, validateRange = 1:5000, 5001:10000

function minibatch(x, y, indexRange)
    xBatch = Array{Float32}(undef, size(x[1])..., 1, length(indexRange))
    for i in 1:length(indexRange)
        xBatch[:, :, :, i] = Float32.(x[indexRange[i]])
    end
    return (xBatch, onehotbatch(y[indexRange], 0:9))
end

trainLabels = MNIST.labels()[trainRange]
trainImgs = MNIST.images()[trainRange]
mbIdxs = Iterators.partition(1:length(trainImgs), batchSize)
trainSet = [minibatch(trainImgs, trainLabels, bi) for bi in mbIdxs]

validateLabels = MNIST.labels()[validateRange]
validateImgs = MNIST.images()[validateRange]
validateSet = minibatch(validateImgs, validateLabels, 1:length(validateImgs))

model1= Chain(flatten, Dense(784, 200,relu),Dense(200, 100,tanh),
				Dense(100, 10,sigmoid), softmax)

model2= Chain(Conv((5, 5), 1=>8, relu), MaxPool((2,2)),
                Conv((3, 3), 8=>16, relu), MaxPool((2,2)),
                flatten, Dense(400, 10), softmax)

opt1 = ADAM(eta); opt2 = ADAM(eta)
accuracyPaths = [[],[]]
accuracy(x, y, model) = mean(onecold(model(x)) .== onecold(y))
loss(x, y, model) = crossentropy(model(x), y)
cbF1() = push!(accuracyPaths[1],accuracy(validateSet..., model1))
cbF2() = push!(accuracyPaths[2],accuracy(validateSet..., model2))

model1(trainSet[1][1]); model2(trainSet[1][1])
for _ in 1:epochs
    Flux.train!((x,y)->loss(x,y,model1), params(model1), trainSet, opt1, cb=cbF1)
    Flux.train!((x,y)->loss(x,y,model2), params(model2), trainSet, opt2, cb=cbF2)
	print(".")
end

println("\nModel1 (Dense) accuracy = ", accuracy(validateSet..., model1))
println("Model2 (Convolutional) accuracy = ", accuracy(validateSet..., model2))
plot(accuracyPaths,label = ["Dense" "Convolutional"],
	ylim=(0.7,1.0), xlabel="Batch number", ylabel = "Validation Accuracy")
```



* Basic stuff with GLM (again) - examples of Metaprogramming here.
* Usage of black box neural network `MetalHead.jl`  (motivation - we won't do more with Neural Networks)
* Least squares `pinv()` on MNIST or similar.
* Quantifing accuracy for classfication (accuracy, precision, recall, F1, confusion matrix)

# Tree based models 

* Hand made decision tree on simple dataset.
* Decision trees
* Boosting 
* Random forests

# Tips for impelmenting random forests.

* ???


